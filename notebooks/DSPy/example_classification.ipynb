{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.11.11 64-bit ('logdelta': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5c43542333abb9a778fb4bad4331b915f4ad0467739e36f7d4282c1fec89b507"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/antti.immonen/anaconda3/envs/logdelta/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "source": [
    "The goal of this notebook is to try to see which models available in OpenRouter's API (or some other API) could be beneficial for generating explanation labels for the anomalies. The assumption here is that **certain LLM's** are better than others in making inference about (supercomputer generaated) log based data, either due to their **architecture or the data seen during training.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    Unnamed: 0                                               text       labels\n0            0  373746 node-121 action error 1085979750 1 halt...  application\n1            1  373800 node-147 action error 1085979770 1 halt...  application\n2            2  - 1131576210 2005.11.09 bn549 nov 9 14:43:30 b...  application\n3            3  366588 node-198 unix.hw state_change.unavailab...  application\n4            4  12-18 18:31:06.771 1795 1808 v activity manage...  application\n..         ...                                                ...          ...\n92          92  - 1131577116 2005.11.09 cn10 nov 9 14:58:36 cn...        other\n93          93  - 1131579082 2005.11.09 dn211 nov 9 15:31:22 d...        other\n94          94  - 1131577356 2005.11.09 an532 nov 9 15:02:36 a...        other\n95          95  - 1131576074 2005.11.09 cn4 nov 9 14:41:14 cn4...        other\n96          96  2015-10-18 18:20:19,151 info [ thread-111] org...        other\n\n[97 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Labeling from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10254958\n",
    "# Repo: https://github.com/Pranjal-Gupta2/learning-representations-on-logs-for-aiops\n",
    "\n",
    "# Read with pandas\n",
    "pd_train = pd.read_excel(\"./data/fc_public_train_30.xlsx\", sheet_name=0)\n",
    "pd_test = pd.read_excel(\"./data/fc_public_test.xlsx\", sheet_name=0)\n",
    "\n",
    "# Convert to Polars\n",
    "#df_train = pl.from_pandas(pd_df)\n",
    "#df_test = pl.from_pandas(pd_df_test)\n",
    "\n",
    "print(pd_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "assert api_key != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyLabeler(dspy.Signature):\n",
    "    \"\"\"Label the anomaly based on the text.\"\"\"\n",
    "    text: str = dspy.InputField()\n",
    "    label: Literal['application', 'authentication', 'io', 'memory', 'network', 'other', ] = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_examples(df_arg):\n",
    "    examples = []\n",
    "    for _, row in df_arg.iterrows():\n",
    "        content = row['text']\n",
    "        label = row['labels']\n",
    "        example = dspy.Example(text=content, label=label).with_inputs(\"text\", \"label\")\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples\n",
    "\n",
    "examples = create_examples(pd_train)\n",
    "for ex in examples[:5]:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = (lambda x, y, trace=None: x.label == y.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_trainset = [ex.with_inputs(\"text\") for ex in create_examples(pd_train)]\n",
    "converted_testset = [ex.with_inputs(\"text\") for ex in create_examples(pd_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_labeler = dspy.ChainOfThought(AnomalyLabeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = anomaly_labeler\n",
    "\n",
    "    def forward(self, content):\n",
    "        return self.prog(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen based on Openrouter's models and https://livebench.ai/#/\n",
    "models = [\n",
    "        \"openrouter/meta-llama/llama-3-8b-instruct:extended\",\n",
    "        \"openrouter/microsoft/wizardlm-2-8x22b:nitro\",\n",
    "        \"openrouter/deepseek/deepseek-r1:free\",\n",
    "        \"openrouter/openai/o1\",\n",
    "        \"openrouter/openai/o3-mini-high\",\n",
    "        \"openrouter/qwen/qwen-2.5-coder-32b-instruct\",\n",
    "        \"openrouter/mistralai/mistral-7b-instruct:free\",\n",
    "        \"openrouter/anthropic/claude-3.7-sonnet:thinking\",\n",
    "        \"openrouter/aion-labs/aion-1.0\",\n",
    "        \"openrouter/google/gemini-2.0-flash-lite-001\"\n",
    "        ]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Hello! How can I assist you today?']\n"
     ]
    }
   ],
   "source": [
    "model = models[2]\n",
    "lm = dspy.LM(model, api_key=api_key)\n",
    "print(lm(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Metric: 65.00 / 97 (67.0%): 100%|██████████| 97/97 [04:49<00:00,  2.99s/it]2025/03/10 01:10:13 INFO dspy.evaluate.evaluate: Average Metric: 65 / 97 (67.0%)\n",
      "\n",
      "cost: 0.12780902000000002 dollars\n"
     ]
    }
   ],
   "source": [
    "evaluate = dspy.Evaluate(devset=converted_trainset, num_threads=8, display_progress=True, display_table=False, return_outputs=True)\n",
    "score, outputs = evaluate(anomaly_labeler, metric=metric)\n",
    "\n",
    "cost = [x['cost'] for x in lm.history if x['cost']]\n",
    "print(f\"cost: {sum(cost)} dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "67.01\nThe error message indicates a connection refusal when trying to connect to the console. Connection refusal (state = refused) typically points to a network-related issue, such as a service not listening on the expected port or network accessibility problems. This aligns with the 'network' category.\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(outputs[0][1].reasoning)"
   ]
  },
  {
   "source": [
    "Using the CoT-module is quite costly, let's see how regular `Predict` compares."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_labeler_pred = dspy.Predict(AnomalyLabeler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Metric: 64.00 / 97 (66.0%): 100%|██████████| 97/97 [02:59<00:00,  1.85s/it]2025/03/10 01:22:10 INFO dspy.evaluate.evaluate: Average Metric: 64 / 97 (66.0%)\n",
      "\n",
      "cost: 0.20056298000000009 dollars\n"
     ]
    }
   ],
   "source": [
    "evaluate = dspy.Evaluate(devset=converted_trainset, num_threads=8, display_progress=True, display_table=False, return_outputs=True)\n",
    "score, outputs = evaluate(anomaly_labeler_pred, metric=metric)\n",
    "\n",
    "cost = [x['cost'] for x in lm.history if x['cost']]\n",
    "print(f\"cost: {sum(cost)} dollars\")"
   ]
  },
  {
   "source": [
    "OK seems somewhat the same and slightly cheaper."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Evaluating model: openrouter/meta-llama/llama-3-8b-instruct:extended\n",
      "Average Metric: 61.00 / 97 (62.9%): 100%|██████████| 97/97 [00:06<00:00, 15.91it/s]2025/03/10 01:26:55 INFO dspy.evaluate.evaluate: Average Metric: 61 / 97 (62.9%)\n",
      "/var/folders/y4/9dghc3r56g78smx_zwddbb2c0000gn/T/ipykernel_19750/1931150890.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({\n",
      "\n",
      "Score: 62.89\n",
      "Cost: $0.0000\n",
      "Runtime: 6.19 seconds\n",
      "\n",
      "\n",
      "Evaluating model: openrouter/microsoft/wizardlm-2-8x22b:nitro\n",
      "Average Metric: 64.00 / 88 (72.7%):  91%|█████████ | 88/97 [00:11<00:01,  5.95it/s]2025/03/10 01:27:07 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '- 1131579160 2005.11.09 cn6 nov 9 15:32:40 cn6/cn6 kernel: uhci_hcd 0000:00:1d.0: uhci host controller', 'label': 'other'}) (input_keys={'text'}): 'list' object has no attribute 'items'. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 66.00 / 95 (69.5%):  99%|█████████▉| 96/97 [00:15<00:00,  3.38it/s]2025/03/10 01:27:12 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '- 1131577116 2005.11.09 cn10 nov 9 14:58:36 cn10/cn10 kernel: uhci_hcd 0000:00:1d.0: uhci host controller', 'label': 'other'}) (input_keys={'text'}): 'list' object has no attribute 'items'. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 66.00 / 95 (69.5%): 100%|██████████| 97/97 [00:16<00:00,  5.84it/s]2025/03/10 01:27:12 INFO dspy.evaluate.evaluate: Average Metric: 66.0 / 97 (68.0%)\n",
      "\n",
      "Score: 68.04\n",
      "Cost: $0.0000\n",
      "Runtime: 16.63 seconds\n",
      "\n",
      "\n",
      "Evaluating model: openrouter/deepseek/deepseek-r1\n",
      "Average Metric: 64.00 / 97 (66.0%): 100%|██████████| 97/97 [00:00<00:00, 231.46it/s]2025/03/10 01:27:12 INFO dspy.evaluate.evaluate: Average Metric: 64 / 97 (66.0%)\n",
      "/var/folders/y4/9dghc3r56g78smx_zwddbb2c0000gn/T/ipykernel_19750/1931150890.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({\n",
      "\n",
      "Score: 65.98\n",
      "Cost: $0.0000\n",
      "Runtime: 0.47 seconds\n",
      "\n",
      "\n",
      "Evaluating model: openrouter/openai/o1\n",
      "Error evaluating model openrouter/openai/o1: OpenAI's reasoning models require passing temperature=1.0 and max_tokens >= 5000 to `dspy.LM(...)`\n",
      "\n",
      "\n",
      "Evaluating model: openai/o3-mini-high\n",
      "Error evaluating model openai/o3-mini-high: OpenAI's reasoning models require passing temperature=1.0 and max_tokens >= 5000 to `dspy.LM(...)`\n",
      "\n",
      "\n",
      "Evaluating model: openrouter/qwen/qwen-2.5-coder-32b-instruct\n",
      "Average Metric: 59.00 / 97 (60.8%): 100%|██████████| 97/97 [00:11<00:00,  8.48it/s]2025/03/10 01:27:24 INFO dspy.evaluate.evaluate: Average Metric: 59 / 97 (60.8%)\n",
      "\n",
      "Score: 60.82\n",
      "Cost: $0.0052\n",
      "Runtime: 11.49 seconds\n",
      "\n",
      "\n",
      "Evaluating model: openrouter/mistralai/mistral-7b-instruct:free\n",
      "Average Metric: 12.00 / 20 (60.0%):  20%|█▉        | 19/97 [00:03<00:10,  7.56it/s]2025/03/10 01:27:27 ERROR dspy.utils.parallelizer: Error processing item Example({'text': ' dec 12 21:44:26 labsz sshd[31685]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=218.106.244.101 user=server', 'label': 'authentication'}) (input_keys={'text'}): the JSON object must be str, bytes or bytearray, not NoneType. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 12.00 / 20 (60.0%):  22%|██▏       | 21/97 [00:03<00:09,  7.78it/s]2025/03/10 01:27:27 ERROR dspy.utils.parallelizer: Error processing item Example({'text': ' dec 12 04:37:44 labsz sshd[14843]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=42.159.145.29 user=backup', 'label': 'authentication'}) (input_keys={'text'}): the JSON object must be str, bytes or bytearray, not NoneType. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 12.00 / 20 (60.0%):  22%|██▏       | 21/97 [00:03<00:09,  7.78it/s]2025/03/10 01:27:27 ERROR dspy.utils.parallelizer: Error processing item Example({'text': ' dec 31 09:07:18 labsz sshd[1616]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=95.188.84.199 user=git', 'label': 'authentication'}) (input_keys={'text'}): the JSON object must be str, bytes or bytearray, not NoneType. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 12.00 / 20 (60.0%):  23%|██▎       | 22/97 [00:03<00:09,  7.78it/s]2025/03/10 01:27:28 ERROR dspy.utils.parallelizer: Error processing item Example({'text': ' jan 2 06:46:12 labsz sshd[27266]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=195.154.37.122 user=uucp', 'label': 'authentication'}) (input_keys={'text'}): the JSON object must be str, bytes or bytearray, not NoneType. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 12.00 / 20 (60.0%):  25%|██▍       | 24/97 [00:03<00:07,  9.29it/s]/var/folders/y4/9dghc3r56g78smx_zwddbb2c0000gn/T/ipykernel_19750/1931150890.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({\n",
      "Error evaluating model openrouter/mistralai/mistral-7b-instruct:free: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "\n",
      "\n",
      "Evaluating model: openrouter/anthropic/claude-3.7-sonnet:thinking\n",
      "Average Metric: 1.00 / 5 (20.0%):   4%|▍         | 4/97 [00:03<01:04,  1.43it/s]2025/03/10 01:27:34 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '24714 node-227 unix.hw state_change.unavailable 1100840859 1 component state change: component \\\\042alt0\\\\042 is in the unavailable state (hwid=3455)', 'label': 'application'}) (input_keys={'text'}): 1 validation error for literal['application','authentication','io','memory','network','other']\n",
      "  Input should be 'application', 'authentication', 'io', 'memory', 'network' or 'other' [type=literal_error, input_value='hardware', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 3.00 / 8 (37.5%):   9%|▉         | 9/97 [00:05<00:36,  2.43it/s]2025/03/10 01:27:35 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '401531 node-158 unix.hw state_change.unavailable 1142550402 1 component state change: component \\\\042alt0\\\\042 is in the unavailable state (hwid=4442)', 'label': 'application'}) (input_keys={'text'}): 1 validation error for literal['application','authentication','io','memory','network','other']\n",
      "  Input should be 'application', 'authentication', 'io', 'memory', 'network' or 'other' [type=literal_error, input_value='hardware', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 5.00 / 10 (50.0%):  11%|█▏        | 11/97 [00:05<00:35,  2.43it/s]2025/03/10 01:27:35 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '366588 node-198 unix.hw state_change.unavailable 1085100840 1 component state change: component \\\\042alt0\\\\042 is in the unavailable state (hwid=2748)', 'label': 'application'}) (input_keys={'text'}): 1 validation error for literal['application','authentication','io','memory','network','other']\n",
      "  Input should be 'application', 'authentication', 'io', 'memory', 'network' or 'other' [type=literal_error, input_value='hardware', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 57.00 / 71 (80.3%):  75%|███████▌  | 73/97 [00:17<00:06,  3.91it/s]2025/03/10 01:27:47 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '- 1131579801 2005.11.09 bn308 nov 9 15:43:21 bn308/bn308 kernel: uhci_hcd 0000:00:1d.0: uhci host controller', 'label': 'other'}) (input_keys={'text'}): the JSON object must be str, bytes or bytearray, not NoneType. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 58.00 / 93 (62.4%): 100%|██████████| 97/97 [00:24<00:00,  3.89it/s]2025/03/10 01:27:54 INFO dspy.evaluate.evaluate: Average Metric: 58.0 / 97 (59.8%)\n",
      "\n",
      "Score: 59.79\n",
      "Cost: $0.1166\n",
      "Runtime: 24.96 seconds\n",
      "\n",
      "\n",
      "Evaluating model: openrouter/aion-labs/aion-1.0\n",
      "Average Metric: 56.00 / 68 (82.4%):  70%|███████   | 68/97 [00:45<00:25,  1.14it/s]2025/03/10 01:28:41 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '2015-10-18 18:05:45,281 warn [ response processor for block bp-1347369012-10.190.173.170-1444972147527:blk_1073743509_2728] org.apache.hadoop.hdfs.dfs client: slow read processor read fields took 54719ms (threshold=30000ms); ack: seqno: -2 status: success status: error downstream ack time nanos: 0, targets: [10.86.164.15:50010, 10.86.169.121:50010]', 'label': 'io'}) (input_keys={'text'}): 'list' object has no attribute 'items'. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 57.00 / 69 (82.6%):  72%|███████▏  | 70/97 [00:48<00:33,  1.25s/it]2025/03/10 01:28:43 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '081111 030115 18071 info dfs. data node$ block receiver: receiving empty packet for block blk_7717782362699139185', 'label': 'network'}) (input_keys={'text'}): 'list' object has no attribute 'items'. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 61.00 / 78 (78.2%):  82%|████████▏ | 80/97 [00:55<00:08,  1.98it/s]2025/03/10 01:28:53 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '081111 092306 25557 info dfs. data node$ block receiver: receiving empty packet for block blk_8002845712641716887', 'label': 'network'}) (input_keys={'text'}): 'list' object has no attribute 'items'. Set `provide_traceback=True` to see the stack trace.\n",
      "Average Metric: 62.00 / 94 (66.0%): 100%|██████████| 97/97 [01:14<00:00,  1.30it/s]2025/03/10 01:29:09 INFO dspy.evaluate.evaluate: Average Metric: 62.0 / 97 (63.9%)\n",
      "\n",
      "Score: 63.92\n",
      "Cost: $0.0000\n",
      "Runtime: 74.93 seconds\n",
      "\n",
      "\n",
      "Evaluating model: google/gemini-2.0-flash-lite-001\n",
      "  0%|          | 0/97 [00:00<?, ?it/s]2025/03/10 01:29:09 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '12-18 18:31:06.771 1795 1808 v activity manager: attempted to start a foreground service ( component info {com.sankuai.meituan/com.dianping.base.push.pushservice.dp.dp push service} ) with a broken notification (no icon: notification(pri=0 content view=null vibrate=null sound=null defaults=0x0 flags=0x40 color=0x00000000 vis=private))', 'label': 'application'}) (input_keys={'text'}): litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-2.0-flash-lite-001\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers. Set `provide_traceback=True` to see the stack trace.\n",
      "2025/03/10 01:29:09 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '373746 node-121 action error 1085979750 1 halt (command 2991) error: couldn\\\\047t connect to console (state = refused)', 'label': 'application'}) (input_keys={'text'}): litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-2.0-flash-lite-001\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers. Set `provide_traceback=True` to see the stack trace.\n",
      "2025/03/10 01:29:09 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '366588 node-198 unix.hw state_change.unavailable 1085100840 1 component state change: component \\\\042alt0\\\\042 is in the unavailable state (hwid=2748)', 'label': 'application'}) (input_keys={'text'}): litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-2.0-flash-lite-001\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers. Set `provide_traceback=True` to see the stack trace.\n",
      "2025/03/10 01:29:09 ERROR dspy.utils.parallelizer: Error processing item Example({'text': '373815 node-154 action error 1085979781 1 halt (command 2992) error: couldn\\\\047t connect to console (state = refused)', 'label': 'application'}) (input_keys={'text'}): litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-2.0-flash-lite-001\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers. Set `provide_traceback=True` to see the stack trace.\n",
      "Error evaluating model google/gemini-2.0-flash-lite-001: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-2.0-flash-lite-001\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\n",
      "\n",
      "Final Evaluation Results:\n",
      "                                               model  score      cost  \\\n",
      "1        openrouter/microsoft/wizardlm-2-8x22b:nitro  68.04         0   \n",
      "2                    openrouter/deepseek/deepseek-r1  65.98         0   \n",
      "8                      openrouter/aion-labs/aion-1.0  63.92         0   \n",
      "0  openrouter/meta-llama/llama-3-8b-instruct:exte...  62.89         0   \n",
      "5        openrouter/qwen/qwen-2.5-coder-32b-instruct  60.82  0.005176   \n",
      "7    openrouter/anthropic/claude-3.7-sonnet:thinking  59.79  0.116604   \n",
      "3                               openrouter/openai/o1    NaN      None   \n",
      "4                                openai/o3-mini-high    NaN      None   \n",
      "6      openrouter/mistralai/mistral-7b-instruct:free    NaN      None   \n",
      "9                   google/gemini-2.0-flash-lite-001    NaN      None   \n",
      "\n",
      "     runtime                                              error  \n",
      "1  16.628234                                                NaN  \n",
      "2   0.470630                                                NaN  \n",
      "8  74.925085                                                NaN  \n",
      "0   6.191946                                                NaN  \n",
      "5  11.493101                                                NaN  \n",
      "7  24.959054                                                NaN  \n",
      "3        NaN  OpenAI's reasoning models require passing temp...  \n",
      "4        NaN  OpenAI's reasoning models require passing temp...  \n",
      "6        NaN  the JSON object must be str, bytes or bytearra...  \n",
      "9        NaN  litellm.BadRequestError: LLM Provider NOT prov...  \n",
      "/var/folders/y4/9dghc3r56g78smx_zwddbb2c0000gn/T/ipykernel_19750/1931150890.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=['model', 'score', 'cost', 'runtime'])\n",
    "\n",
    "for model in models:\n",
    "    try:\n",
    "        print(f\"\\n\\nEvaluating model: {model}\")\n",
    "        lm = dspy.LM(model, api_key=api_key)\n",
    "        dspy.configure(lm=lm)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Evaluate model\n",
    "        evaluate = dspy.Evaluate(devset=converted_trainset, num_threads=8, display_progress=True, display_table=False, return_outputs=True)\n",
    "        score, outputs = evaluate(anomaly_labeler_pred, metric=metric)\n",
    "        \n",
    "        runtime = time.time() - start_time\n",
    "        cost = sum([x['cost'] for x in lm.history if 'cost' in x and x['cost']])\n",
    "        \n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Cost: ${cost:.4f}\")\n",
    "        print(f\"Runtime: {runtime:.2f} seconds\")\n",
    "        \n",
    "        results_df = pd.concat([results_df, pd.DataFrame({\n",
    "            'model': [model],\n",
    "            'score': [score],\n",
    "            'cost': [cost],\n",
    "            'runtime': [runtime]\n",
    "        })], ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model {model}: {str(e)}\")\n",
    "        results_df = pd.concat([results_df, pd.DataFrame({\n",
    "            'model': [model],\n",
    "            'score': [None],\n",
    "            'cost': [None],\n",
    "            'runtime': [None],\n",
    "            'error': [str(e)]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('model_evaluation_results.csv', index=False)\n",
    "\n",
    "print(\"\\n\\nFinal Evaluation Results:\")\n",
    "print(results_df.sort_values(by='score', ascending=False))"
   ]
  },
  {
   "source": [
    "Missing params for OpenAI + Gemini models, let's fix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Metric: 63.00 / 97 (64.9%): 100%|██████████| 97/97 [00:40<00:00,  2.39it/s]2025/03/10 01:33:52 INFO dspy.evaluate.evaluate: Average Metric: 63 / 97 (64.9%)\n",
      "\n",
      "cost: 1.6330950000000009 dollars\n"
     ]
    }
   ],
   "source": [
    "lm = dspy.LM(\"openrouter/openai/o1\", api_key=api_key, temperature=1.0, max_tokens=5000)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=converted_trainset, num_threads=8, display_progress=True, display_table=False, return_outputs=True)\n",
    "score, outputs = evaluate(anomaly_labeler_pred, metric=metric)\n",
    "\n",
    "cost = [x['cost'] for x in lm.history if x['cost']]\n",
    "print(f\"cost: {sum(cost)} dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Metric: 65.00 / 97 (67.0%): 100%|██████████| 97/97 [01:11<00:00,  1.36it/s]2025/03/10 01:36:09 INFO dspy.evaluate.evaluate: Average Metric: 65 / 97 (67.0%)\n",
      "\n",
      "cost: 0 dollars\n"
     ]
    }
   ],
   "source": [
    "lm = dspy.LM(\"openrouter/openai/o3-mini-high\", api_key=api_key, temperature=1.0, max_tokens=5000)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=converted_trainset, num_threads=8, display_progress=True, display_table=False, return_outputs=True)\n",
    "score, outputs = evaluate(anomaly_labeler_pred, metric=metric)\n",
    "\n",
    "cost = [x['cost'] for x in lm.history if x['cost']]\n",
    "print(f\"cost: {sum(cost)} dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Metric: 55.00 / 97 (56.7%): 100%|██████████| 97/97 [00:08<00:00, 11.09it/s]2025/03/10 01:43:32 INFO dspy.evaluate.evaluate: Average Metric: 55 / 97 (56.7%)\n",
      "\n",
      "cost: 0 dollars\n"
     ]
    }
   ],
   "source": [
    "lm = dspy.LM(\"openrouter/google/gemini-2.0-flash-lite-001\", api_key=api_key)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=converted_trainset, num_threads=8, display_progress=True, display_table=False, return_outputs=True)\n",
    "score, outputs = evaluate(anomaly_labeler_pred, metric=metric)\n",
    "\n",
    "cost = [x['cost'] for x in lm.history if x['cost']]\n",
    "print(f\"cost: {sum(cost)} dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Metric: 70.00 / 97 (72.2%): 100%|██████████| 97/97 [00:00<00:00, 849.74it/s]2025/03/10 02:36:57 INFO dspy.evaluate.evaluate: Average Metric: 70 / 97 (72.2%)\n",
      "\n",
      "cost: 0 dollars\n"
     ]
    }
   ],
   "source": [
    "lm = dspy.LM(\"openrouter/amazon/nova-micro-v1\", api_key=api_key)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=converted_trainset, num_threads=8, display_progress=True, display_table=False, return_outputs=True)\n",
    "score, outputs = evaluate(anomaly_labeler_pred, metric=metric)\n",
    "\n",
    "cost = [x['cost'] for x in lm.history if x['cost']]\n",
    "print(f\"cost: {sum(cost)} dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
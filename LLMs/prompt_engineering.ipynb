{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "os.chdir(project_root)\n",
    "from utils.helpers import parse_log_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "MODEL = \"meta-llama/llama-3-8b-instruct:free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_logs(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chat_response(message, model = MODEL):\n",
    "    client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Line-level Log anomaly Explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Level\n",
       "INFO     1040\n",
       "WARN      808\n",
       "ERROR     150\n",
       "FATAL       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Hadoop_2k.log_structured.csv\")\n",
    "df.Level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Level</th>\n",
       "      <th>Process</th>\n",
       "      <th>Component</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:01:47,978</td>\n",
       "      <td>INFO</td>\n",
       "      <td>main</td>\n",
       "      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n",
       "      <td>Created MRAppMaster for application appattempt...</td>\n",
       "      <td>E29</td>\n",
       "      <td>Created MRAppMaster for application appattempt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:01:48,963</td>\n",
       "      <td>INFO</td>\n",
       "      <td>main</td>\n",
       "      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n",
       "      <td>Executing with tokens:</td>\n",
       "      <td>E42</td>\n",
       "      <td>Executing with tokens:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:01:48,963</td>\n",
       "      <td>INFO</td>\n",
       "      <td>main</td>\n",
       "      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n",
       "      <td>Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...</td>\n",
       "      <td>E61</td>\n",
       "      <td>Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:01:49,228</td>\n",
       "      <td>INFO</td>\n",
       "      <td>main</td>\n",
       "      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n",
       "      <td>Using mapred newApiCommitter.</td>\n",
       "      <td>E111</td>\n",
       "      <td>Using mapred newApiCommitter.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:01:50,353</td>\n",
       "      <td>INFO</td>\n",
       "      <td>main</td>\n",
       "      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n",
       "      <td>OutputCommitter set in config null</td>\n",
       "      <td>E76</td>\n",
       "      <td>OutputCommitter set in config null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:10:54,202</td>\n",
       "      <td>WARN</td>\n",
       "      <td>LeaseRenewer:msrabi@msra-sa-41:9000</td>\n",
       "      <td>org.apache.hadoop.ipc.Client</td>\n",
       "      <td>Address change detected. Old: msra-sa-41/10.19...</td>\n",
       "      <td>E10</td>\n",
       "      <td>Address change detected. Old: &lt;*&gt;/&lt;*&gt;:&lt;*&gt; New:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:10:54,202</td>\n",
       "      <td>WARN</td>\n",
       "      <td>LeaseRenewer:msrabi@msra-sa-41:9000</td>\n",
       "      <td>org.apache.hadoop.hdfs.LeaseRenewer</td>\n",
       "      <td>Failed to renew lease for [DFSClient_NONMAPRED...</td>\n",
       "      <td>E44</td>\n",
       "      <td>Failed to renew lease for [DFSClient_NONMAPRED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:10:54,546</td>\n",
       "      <td>INFO</td>\n",
       "      <td>RMCommunicator Allocator</td>\n",
       "      <td>org.apache.hadoop.ipc.Client</td>\n",
       "      <td>Retrying connect to server: msra-sa-41:8030. A...</td>\n",
       "      <td>E91</td>\n",
       "      <td>Retrying connect to server: &lt;*&gt;:&lt;*&gt;. Already t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:10:54,546</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>RMCommunicator Allocator</td>\n",
       "      <td>org.apache.hadoop.mapreduce.v2.app.rm.RMContai...</td>\n",
       "      <td>ERROR IN CONTACTING RM.</td>\n",
       "      <td>E38</td>\n",
       "      <td>ERROR IN CONTACTING RM.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>18:10:55,202</td>\n",
       "      <td>WARN</td>\n",
       "      <td>LeaseRenewer:msrabi@msra-sa-41:9000</td>\n",
       "      <td>org.apache.hadoop.ipc.Client</td>\n",
       "      <td>Address change detected. Old: msra-sa-41/10.19...</td>\n",
       "      <td>E10</td>\n",
       "      <td>Address change detected. Old: &lt;*&gt;/&lt;*&gt;:&lt;*&gt; New:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LineId        Date          Time  Level  \\\n",
       "0          1  2015-10-18  18:01:47,978   INFO   \n",
       "1          2  2015-10-18  18:01:48,963   INFO   \n",
       "2          3  2015-10-18  18:01:48,963   INFO   \n",
       "3          4  2015-10-18  18:01:49,228   INFO   \n",
       "4          5  2015-10-18  18:01:50,353   INFO   \n",
       "...      ...         ...           ...    ...   \n",
       "1995    1996  2015-10-18  18:10:54,202   WARN   \n",
       "1996    1997  2015-10-18  18:10:54,202   WARN   \n",
       "1997    1998  2015-10-18  18:10:54,546   INFO   \n",
       "1998    1999  2015-10-18  18:10:54,546  ERROR   \n",
       "1999    2000  2015-10-18  18:10:55,202   WARN   \n",
       "\n",
       "                                  Process  \\\n",
       "0                                    main   \n",
       "1                                    main   \n",
       "2                                    main   \n",
       "3                                    main   \n",
       "4                                    main   \n",
       "...                                   ...   \n",
       "1995  LeaseRenewer:msrabi@msra-sa-41:9000   \n",
       "1996  LeaseRenewer:msrabi@msra-sa-41:9000   \n",
       "1997             RMCommunicator Allocator   \n",
       "1998             RMCommunicator Allocator   \n",
       "1999  LeaseRenewer:msrabi@msra-sa-41:9000   \n",
       "\n",
       "                                              Component  \\\n",
       "0        org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
       "1        org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
       "2        org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
       "3        org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
       "4        org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
       "...                                                 ...   \n",
       "1995                       org.apache.hadoop.ipc.Client   \n",
       "1996                org.apache.hadoop.hdfs.LeaseRenewer   \n",
       "1997                       org.apache.hadoop.ipc.Client   \n",
       "1998  org.apache.hadoop.mapreduce.v2.app.rm.RMContai...   \n",
       "1999                       org.apache.hadoop.ipc.Client   \n",
       "\n",
       "                                                Content EventId  \\\n",
       "0     Created MRAppMaster for application appattempt...     E29   \n",
       "1                                Executing with tokens:     E42   \n",
       "2     Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...     E61   \n",
       "3                         Using mapred newApiCommitter.    E111   \n",
       "4                    OutputCommitter set in config null     E76   \n",
       "...                                                 ...     ...   \n",
       "1995  Address change detected. Old: msra-sa-41/10.19...     E10   \n",
       "1996  Failed to renew lease for [DFSClient_NONMAPRED...     E44   \n",
       "1997  Retrying connect to server: msra-sa-41:8030. A...     E91   \n",
       "1998                            ERROR IN CONTACTING RM.     E38   \n",
       "1999  Address change detected. Old: msra-sa-41/10.19...     E10   \n",
       "\n",
       "                                          EventTemplate  \n",
       "0     Created MRAppMaster for application appattempt...  \n",
       "1                                Executing with tokens:  \n",
       "2     Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...  \n",
       "3                         Using mapred newApiCommitter.  \n",
       "4                    OutputCommitter set in config null  \n",
       "...                                                 ...  \n",
       "1995  Address change detected. Old: <*>/<*>:<*> New:...  \n",
       "1996  Failed to renew lease for [DFSClient_NONMAPRED...  \n",
       "1997  Retrying connect to server: <*>:<*>. Already t...  \n",
       "1998                            ERROR IN CONTACTING RM.  \n",
       "1999  Address change detected. Old: <*>/<*>:<*> New:...  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Log Level: INFO. Process: main. Component: org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor. Content: nodeBlacklistingEnabled:true. EventTemplate: nodeBlacklistingEnabled:true',\n",
       " 'Log Level: INFO. Process: RMCommunicator Allocator. Component: org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator. Content: Reduce slow start threshold not met. completedMapsForReduceSlowstart 1. EventTemplate: Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>',\n",
       " 'Log Level: WARN. Process: LeaseRenewer:msrabi@msra-sa-41:9000. Component: org.apache.hadoop.hdfs.LeaseRenewer. Content: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 238 seconds.  Will retry shortly .... EventTemplate: Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...',\n",
       " 'Log Level: WARN. Process: LeaseRenewer:msrabi@msra-sa-41:9000. Component: org.apache.hadoop.hdfs.LeaseRenewer. Content: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 91 seconds.  Will retry shortly .... EventTemplate: Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ...',\n",
       " 'Log Level: ERROR. Process: RMCommunicator Allocator. Component: org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator. Content: ERROR IN CONTACTING RM.. EventTemplate: ERROR IN CONTACTING RM.',\n",
       " 'Log Level: ERROR. Process: RMCommunicator Allocator. Component: org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator. Content: ERROR IN CONTACTING RM.. EventTemplate: ERROR IN CONTACTING RM.',\n",
       " 'Log Level: FATAL. Process: IPC Server handler 13 on 62270. Component: org.apache.hadoop.mapred.TaskAttemptListenerImpl. Content: Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost. EventTemplate: Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost',\n",
       " 'Log Level: FATAL. Process: IPC Server handler 4 on 62270. Component: org.apache.hadoop.mapred.TaskAttemptListenerImpl. Content: Task: attempt_1445144423722_0020_m_000001_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost. EventTemplate: Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = df.Level.value_counts().keys().tolist()\n",
    "contents = []\n",
    "for cat in categories:\n",
    "    sample_logs = df[df.Level == cat].sample(2)\n",
    "    for i, row in sample_logs.iterrows():\n",
    "        contents.append(f\"Log Level: {row.Level}. Process: {row.Process}. Component: {row.Component}. Content: {row.Content}. EventTemplate: {row.EventTemplate}\")\n",
    "contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The joy of analyzing log messages!\\n\\nIn this log message, we are dealing with the Hadoop MapReduce framework. Specifically, this is a log message from the `RMContainerAllocator` component, which is responsible for allocating containers (i.e., tasks) to reduce nodes in a Hadoop cluster.\\n\\nThe log message is an `INFO` log level, which indicates that this is not an error message, but rather a informative message about the behavior of the system.\\n\\nThe anomaly that stands out is the fact that the \"Reduce slow start threshold not met\". This threshold refers to the maximum number of completed maps (i.e., map tasks) that a reduce task (i.e., reduce process) should allow before it starts processing. This threshold is designed to prevent a reduce task from being overwhelmed by too many map tasks completing too quickly, which could lead to a denial-of-service (DoS) attack or other performance issues.\\n\\nThe log message indicates that the reduce task has not met this threshold, which suggests that the number of completed maps (1) is below the expected threshold. The `completedMapsForReduceSlowstart` value of 1 is a relatively small number, which implies that either:\\n\\n1. The reduce task is not receiving a sufficient number of map tasks to meet the slow start threshold, or\\n2. There is a significant delay or latency in the processing of map tasks, causing the reduce task to not receive enough map tasks to meet the threshold.\\n\\nThe reason for this anomaly is likely due to various factors, such as:\\n\\n* Inadequate map task allocation or scheduling, leading to a low number of map tasks being completed.\\n* Network congestion, latency, or connectivity issues affecting map task processing, resulting in a slower than expected completion rate.\\n* Incorrect configuration of the Hadoop cluster or reduce task, leading to suboptimal performance.\\n\\nTo troubleshoot this issue, it would be necessary to review the Hadoop cluster\\'s configuration, monitor the cluster\\'s performance using tools like `hadoop dfsadmin -report` or `yarn application -list`, and analyze the overall job configuration and its dependencies.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"Detect whether or not there is an anomaly is the log. If so, explain the anomaly and why it happened?\" + \"\\n Log: \" + contents[0]\n",
    "generate_chat_response(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The anomaly detected in the log is a `NoRouteToHostException` which is a fatal error in the Hadoop MapReduce process.\\n\\nThe error message indicates that the IPC (Inter-Process Communication) server handler 13 on port 62270 is unable to connect to `msra-sa-41:9000` due to a socket timeout exception. This means that the handler is trying to establish a connection to the node `msra-sa-41` on port `9000`, but the connection is timing out, and the host is not reachable.\\n\\nThe possible reasons for this anomaly are:\\n\\n1. **Network connectivity issue**: There might be a network connectivity issue between the node running the IPC server handler and `msra-sa-41`. This could be due to a faulty network cable, a misconfigured router, or a network outage.\\n2. **Node not available**: `msra-sa-41` might not be available or might be down, which is causing the connection timeout.\\n3. **Firewall or security restrictions**: There might be firewall or security restrictions in place that are blocking the connection to `msra-sa-41:9000`.\\n4. **Hadoop configuration issue**: There might be an issue with the Hadoop configuration, such as incorrect node information or incorrect port numbers.\\n\\nTo resolve this anomaly, you should:\\n\\n1. Check the network connectivity between the nodes and ensure that there are no issues.\\n2. Verify that `msra-sa-41` is available and reachable.\\n3. Check the firewall and security settings to ensure that there are no restrictions blocking the connection.\\n4. Review the Hadoop configuration to ensure that it is correct and up-to-date.\\n\\nIt is also recommended to check the Hadoop logs for any other errors or warnings that might be related to this issue.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"Detect whether or not there is an anomaly is the log. If so, explain the anomaly and why it happened?\" + \"\\n Log: \" + contents[-1]\n",
    "generate_chat_response(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run-level Log anomaly Explanation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let's find the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "                      Application   Job Type         Issue\n",
      "0  application_1445087491445_0005  WordCount        Normal\n",
      "1  application_1445087491445_0007  WordCount        Normal\n",
      "2  application_1445175094696_0005  WordCount        Normal\n",
      "3  application_1445087491445_0001  WordCount  Machine down\n",
      "4  application_1445087491445_0002  WordCount  Machine down\n"
     ]
    }
   ],
   "source": [
    "#First method: Find the files given the labels\n",
    "\n",
    "lables_dict = parse_log_labels(\"data/Hadoop/abnormal_label.txt\")\n",
    "records = []\n",
    "for job_type, issues in lables_dict.items():\n",
    "    for issue, applications in issues.items():\n",
    "        for app in applications:\n",
    "            records.append({\"Application\": app, \"Job Type\": job_type, \"Issue\": issue})\n",
    "\n",
    "df_logs = pd.DataFrame(records)\n",
    "\n",
    "print(len(df_logs))\n",
    "print(df_logs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978\n",
      "    Job Type     Issue                          run_id  \\\n",
      "0  WordCount  DiskFull  application_1445182159119_0001   \n",
      "1  WordCount  DiskFull  application_1445182159119_0001   \n",
      "2  WordCount  DiskFull  application_1445182159119_0001   \n",
      "3  WordCount  DiskFull  application_1445182159119_0001   \n",
      "4  WordCount  DiskFull  application_1445182159119_0001   \n",
      "\n",
      "                                 container_id  \\\n",
      "0  container_1445182159119_0001_01_000001.log   \n",
      "1  container_1445182159119_0001_01_000002.log   \n",
      "2  container_1445182159119_0001_01_000003.log   \n",
      "3  container_1445182159119_0001_01_000007.log   \n",
      "4  container_1445182159119_0001_01_000006.log   \n",
      "\n",
      "                                             Content  \n",
      "0  2015-10-19 14:21:32,887 INFO [main] org.apache...  \n",
      "1  2015-10-19 14:21:43,552 INFO [main] org.apache...  \n",
      "2  2015-10-19 14:21:43,739 INFO [main] org.apache...  \n",
      "3  2015-10-19 14:21:43,614 INFO [main] org.apache...  \n",
      "4  2015-10-19 14:21:43,739 INFO [main] org.apache...  \n"
     ]
    }
   ],
   "source": [
    "# Second method: Given the files, parse the file names and find the corresponding labels\n",
    "files  = os.listdir(\"data/Hadoop/\")\n",
    "data = []\n",
    "for f in files: \n",
    "    if f.startswith(\"WordCount\") or f.startswith(\"PageRank\"):\n",
    "        job_type = f.split(\"_\")[0]\n",
    "        issue = f.split(\"_\")[1]\n",
    "        id = \"_\".join(f.split(\"_\")[2:])\n",
    "        for container in os.listdir(f\"data/Hadoop/{f}\"):\n",
    "            if container.endswith(\".log\"):\n",
    "                content = read_logs(f\"data/Hadoop/{f}/{container}\")\n",
    "                data.append({\"Job Type\": job_type, \"Issue\": issue, \"run_id\": id, \"container_id\": container, \"Content\": content})\n",
    "df_files = pd.DataFrame(data)\n",
    "print(len(df_files))\n",
    "        \n",
    "print(df_files.head())\n",
    "df_files.to_csv(\"data/Hadoop_logs_combined.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Issue</th>\n",
       "      <th>run_id</th>\n",
       "      <th>container_id</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WordCount</td>\n",
       "      <td>DiskFull</td>\n",
       "      <td>application_1445182159119_0001</td>\n",
       "      <td>container_1445182159119_0001_01_000001.log</td>\n",
       "      <td>2015-10-19 14:21:32,887 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WordCount</td>\n",
       "      <td>DiskFull</td>\n",
       "      <td>application_1445182159119_0001</td>\n",
       "      <td>container_1445182159119_0001_01_000002.log</td>\n",
       "      <td>2015-10-19 14:21:43,552 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WordCount</td>\n",
       "      <td>DiskFull</td>\n",
       "      <td>application_1445182159119_0001</td>\n",
       "      <td>container_1445182159119_0001_01_000003.log</td>\n",
       "      <td>2015-10-19 14:21:43,739 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WordCount</td>\n",
       "      <td>DiskFull</td>\n",
       "      <td>application_1445182159119_0001</td>\n",
       "      <td>container_1445182159119_0001_01_000007.log</td>\n",
       "      <td>2015-10-19 14:21:43,614 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WordCount</td>\n",
       "      <td>DiskFull</td>\n",
       "      <td>application_1445182159119_0001</td>\n",
       "      <td>container_1445182159119_0001_01_000006.log</td>\n",
       "      <td>2015-10-19 14:21:43,739 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>PageRank</td>\n",
       "      <td>MachineDown</td>\n",
       "      <td>application_1445062781478_0014</td>\n",
       "      <td>container_1445062781478_0014_01_000011.log</td>\n",
       "      <td>2015-10-17 15:41:50,715 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>PageRank</td>\n",
       "      <td>MachineDown</td>\n",
       "      <td>application_1445062781478_0014</td>\n",
       "      <td>container_1445062781478_0014_01_000010.log</td>\n",
       "      <td>2015-10-17 15:41:15,588 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>PageRank</td>\n",
       "      <td>MachineDown</td>\n",
       "      <td>application_1445062781478_0014</td>\n",
       "      <td>container_1445062781478_0014_01_000004.log</td>\n",
       "      <td>2015-10-17 15:40:39,486 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>PageRank</td>\n",
       "      <td>MachineDown</td>\n",
       "      <td>application_1445062781478_0014</td>\n",
       "      <td>container_1445062781478_0014_01_000009.log</td>\n",
       "      <td>2015-10-17 15:41:16,586 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>PageRank</td>\n",
       "      <td>MachineDown</td>\n",
       "      <td>application_1445062781478_0014</td>\n",
       "      <td>container_1445062781478_0014_01_000008.log</td>\n",
       "      <td>2015-10-17 15:40:56,768 INFO [main] org.apache...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>978 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Job Type        Issue                          run_id  \\\n",
       "0    WordCount     DiskFull  application_1445182159119_0001   \n",
       "1    WordCount     DiskFull  application_1445182159119_0001   \n",
       "2    WordCount     DiskFull  application_1445182159119_0001   \n",
       "3    WordCount     DiskFull  application_1445182159119_0001   \n",
       "4    WordCount     DiskFull  application_1445182159119_0001   \n",
       "..         ...          ...                             ...   \n",
       "973   PageRank  MachineDown  application_1445062781478_0014   \n",
       "974   PageRank  MachineDown  application_1445062781478_0014   \n",
       "975   PageRank  MachineDown  application_1445062781478_0014   \n",
       "976   PageRank  MachineDown  application_1445062781478_0014   \n",
       "977   PageRank  MachineDown  application_1445062781478_0014   \n",
       "\n",
       "                                   container_id  \\\n",
       "0    container_1445182159119_0001_01_000001.log   \n",
       "1    container_1445182159119_0001_01_000002.log   \n",
       "2    container_1445182159119_0001_01_000003.log   \n",
       "3    container_1445182159119_0001_01_000007.log   \n",
       "4    container_1445182159119_0001_01_000006.log   \n",
       "..                                          ...   \n",
       "973  container_1445062781478_0014_01_000011.log   \n",
       "974  container_1445062781478_0014_01_000010.log   \n",
       "975  container_1445062781478_0014_01_000004.log   \n",
       "976  container_1445062781478_0014_01_000009.log   \n",
       "977  container_1445062781478_0014_01_000008.log   \n",
       "\n",
       "                                               Content  \n",
       "0    2015-10-19 14:21:32,887 INFO [main] org.apache...  \n",
       "1    2015-10-19 14:21:43,552 INFO [main] org.apache...  \n",
       "2    2015-10-19 14:21:43,739 INFO [main] org.apache...  \n",
       "3    2015-10-19 14:21:43,614 INFO [main] org.apache...  \n",
       "4    2015-10-19 14:21:43,739 INFO [main] org.apache...  \n",
       "..                                                 ...  \n",
       "973  2015-10-17 15:41:50,715 INFO [main] org.apache...  \n",
       "974  2015-10-17 15:41:15,588 INFO [main] org.apache...  \n",
       "975  2015-10-17 15:40:39,486 INFO [main] org.apache...  \n",
       "976  2015-10-17 15:41:16,586 INFO [main] org.apache...  \n",
       "977  2015-10-17 15:40:56,768 INFO [main] org.apache...  \n",
       "\n",
       "[978 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Issue\n",
       "MachineDown             523\n",
       "Normal                  167\n",
       "DiskFull                152\n",
       "NetworkDisconnection    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files.Issue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Disk Full'\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HADOOP_ANOMALIES = [\"Machine Down\", \"Network Disconnection\", \"Disk Full\"]\n",
    "\n",
    "PROMPT = f\"\"\"You are a professional Hadoop software engineer. You are tasked with classifying the log types into one of the following categories: {HADOOP_ANOMALIES}.\n",
    "Do not provide any explanation. Your output should be the class of the log.\n",
    "\"\"\"\n",
    "\n",
    "generate_chat_response(PROMPT + \"\\n\" + df_files.Content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Type                                                 PageRank\n",
      "Issue                                        NetworkDisconnection\n",
      "run_id                             application_1445144423722_0022\n",
      "container_id           container_1445144423722_0022_01_000011.log\n",
      "Content         2015-10-18 18:02:10,840 INFO [main] org.apache...\n",
      "Name: 127, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Disk Full'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_files[df_files.Issue == \"NetworkDisconnection\"].iloc[0])\n",
    "\n",
    "generate_chat_response(PROMPT + \"\\n\" + df_files[df_files.Issue == \"NetworkDisconnection\"].iloc[0].Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Type                                                WordCount\n",
      "Issue                                                 MachineDown\n",
      "run_id                             application_1445087491445_0008\n",
      "container_id           container_1445087491445_0008_01_000013.log\n",
      "Content         2015-10-17 22:31:25,692 INFO [main] org.apache...\n",
      "Name: 12, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'Disk Full'\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_files[df_files.Issue == \"MachineDown\"].iloc[0])\n",
    "generate_chat_response(PROMPT + \"\\n\" + df_files[df_files.Issue == \"MachineDown\"].iloc[0].Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG based Anomaly Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

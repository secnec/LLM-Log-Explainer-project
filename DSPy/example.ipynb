{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "dspy-example",
   "display_name": "dspy",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DSPy example about modules and working with log data\n",
    "\n",
    "The goal of the notebook is to give a brief introduction to the [DSPy](https://dspy.ai) framework.\n",
    "\n",
    "If you don't have `dspy` installed, either run `!pip install dspy` in the cell below in your chosen environment or create a new one using, e.g., conda:\n",
    "```\n",
    "conda create -n dspy-example python=3.9\n",
    "conda activate dspy-example\n",
    "conda install ipykernel\n",
    "pip install dspy pandas\n",
    "python -m ipykernel install --user --name=dspy-example --display-name \"dspy-example\"\n",
    "```\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import dspy\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "source": [
    "## Setting up the pipeline\n",
    "\n",
    "We will be using [OpenRouter](https://openrouter.ai/) to communicate with different LLMs. [This](https://models.litellm.ai/) link provides a list of all models that are usable via OpenRouter API (do `CTRL+F` \"openrouter\" for example). By clicking a certain model in this list you can see certain specs of the models, e.g., context length and price per token processed/generated.\n",
    "\n",
    "Let's get started by setting out OpenRouter API key into `.env` file under `OPENROUTER_API_KEY`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Access the API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "assert api_key != None"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "A good way to get started, debug and try out the DSPy is to use a free model, so let's choose meta's 8B parameter Llama model.\n",
    "\n",
    "N.B.: Although these models are free to use, the number of API calls per minute are limited [as follows](https://openrouter.ai/docs/api-reference/limits)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model name\n",
    "model2 = \"openrouter/meta-llama/llama-3-8b-instruct:free\"\n",
    "model = \"openrouter/meta-llama/llama-3-8b-instruct:extended\""
   ]
  },
  {
   "source": [
    "Next, we need to setup this language model to be part of our pipeline."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(model, api_key=api_key)"
   ]
  },
  {
   "source": [
    "We can see if the pipeline works by prompting our pipeline."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\"]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "lm(\"hi\", temperature=0.7)\n"
   ]
  },
  {
   "source": [
    "To make sure that our LLM completion was indeed free, we may check the price of the previous calls:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the cumulated total cost so far: 0 dollars\n"
     ]
    }
   ],
   "source": [
    "cost = [x['cost'] for x in lm.history if x['cost']]\n",
    "print(f\"the cumulated total cost so far: {sum(cost)} dollars\")"
   ]
  },
  {
   "source": [
    "## Signatures\n",
    "\n",
    "DSPy is an acronym of `Declarative Self-improving Python`, and the `Declarative` part comes from the fact that we only specify the expected input-output behaviour/type of a prompt and it's completion via a `Signature` (see [here](https://dspy.ai/learn/programming/signatures/)).\n",
    "\n",
    "A signature can either be declared inline via `input: [A] -> output: [B]` or explicitly as an inherited class\n",
    "```\n",
    "class Emotion(dspy.Signature):\n",
    "    \"\"\"The docstring in DSPy signatures actually matter. \"\"\"\n",
    "    input: [A] = dspy.InputField()\n",
    "    output: [B] = dspy.OutputField()\n",
    "```\n",
    "Note that the docstring is actually passed on to the actual LLM as part of the prompt and is therefore meaningful.\n",
    "\n",
    "## Modules\n",
    "\n",
    "The basic building block to DSPy are [modules](https://dspy.ai/learn/programming/modules/). Essentially, they abstract away common prompt engineering techniques to happen under the hood. \n",
    "\n",
    "We can use a list of ready-made modules like `dspy.Predict` and `dspy.ChainOfThought` or declare our own.\n",
    "\n",
    "To make things more concrete, let's see an example. \n",
    "\n",
    "Assume we wanted to do a binary classification on toxicity.\n",
    "\n",
    "Let us first do this using the inline syntax."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1) Configure lm to be part of our pipeline\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# 2) Sentence to classify\n",
    "statement = \"i hate sundays\"\n",
    "\n",
    "# 3) In-line declarement of expected input/output-types\n",
    "classification = dspy.Predict('sentence: str -> toxic: int')\n",
    "\n",
    "# 4) Call LLM\n",
    "response = classification(sentence=statement)\n",
    "\n",
    "# 5) See response\n",
    "print(response.toxic)"
   ]
  },
  {
   "source": [
    "We could have also done this explicitly as a class, and given toxicity a labeled interpretation instead of 0/1-values:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "toxic\n"
     ]
    }
   ],
   "source": [
    "class ToxicityClassifier(dspy.Signature):\n",
    "    \"\"\"Classify toxicity.\"\"\"\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal['toxic', 'not toxic'] = dspy.OutputField()\n",
    "\n",
    "classification = dspy.Predict(ToxicityClassifier)\n",
    "response = classification(sentence=statement)\n",
    "print(response.sentiment)\n"
   ]
  },
  {
   "source": [
    "What about a little more unambiguous statement?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "statement = \"What led you to that conclusion?\"\n",
    "response = classification(sentence=statement)\n",
    "print(response.sentiment)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "toxic\n"
     ]
    }
   ]
  },
  {
   "source": [
    "Here the classification seems to fail.\n",
    "\n",
    "In the above, the `Predict` is a \"basic predictor\" as a DSPy `Module` instance. For more complex tasks, one wants to use the `ChainOfThought` module. To get a better understanding what's happening under the hood, see [here](https://github.com/stanfordnlp/dspy/blob/main/dspy/predict/chain_of_thought.py).\n",
    "\n",
    "Let's try how a `ChainOfThought` module performs with the latter toxicity classfication task."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "not toxic\n"
     ]
    }
   ],
   "source": [
    "classification_cot = dspy.ChainOfThought(ToxicityClassifier)\n",
    "response_cot = classification_cot(sentence=statement)\n",
    "print(response_cot.sentiment)"
   ]
  },
  {
   "source": [
    "With the `ChainOfThought` module may also study all the responses and their reasonings, i.e., why the output was generated."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the sentence 'What led you to that conclusion?' is not toxic because: The sentence is a question and does not contain any offensive language, so it is not toxic.\n"
     ]
    }
   ],
   "source": [
    "# 3) Access the outputs.\n",
    "print(f\"the sentence '{statement}' is {response_cot.sentiment} because: {response_cot.reasoning}\")"
   ]
  },
  {
   "source": [
    "### Moving onto real data\n",
    "\n",
    "Let's see if we can do classification on actual data. The following data examples are taken from [loghub's GitHub repo](https://github.com/logpai/loghub/tree/master)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 3 rows of Zookeeper_2k.log_structured.csv:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   LineId        Date          Time Level                  Node  \\\n0       1  2015-07-29  17:41:44,747  INFO  QuorumPeer[myid=1]/0   \n1       2  2015-07-29  19:04:12,394  INFO          /10.10.34.11   \n2       3  2015-07-29  19:04:29,071  WARN            SendWorker   \n\n                                  Component   Id  \\\n0     0:0:0:0:0:0:0:2181:FastLeaderElection  774   \n1            3888:QuorumCnxManager$Listener  493   \n2  188978561024:QuorumCnxManager$SendWorker  688   \n\n                                          Content EventId  \\\n0                     Notification time out: 3200     E31   \n1  Received connection request /10.10.34.11:45307     E40   \n2                      Send worker leaving thread     E42   \n\n                          EventTemplate  \n0            Notification time out: <*>  \n1  Received connection request /<*>:<*>  \n2            Send worker leaving thread  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LineId</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Level</th>\n      <th>Node</th>\n      <th>Component</th>\n      <th>Id</th>\n      <th>Content</th>\n      <th>EventId</th>\n      <th>EventTemplate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2015-07-29</td>\n      <td>17:41:44,747</td>\n      <td>INFO</td>\n      <td>QuorumPeer[myid=1]/0</td>\n      <td>0:0:0:0:0:0:0:2181:FastLeaderElection</td>\n      <td>774</td>\n      <td>Notification time out: 3200</td>\n      <td>E31</td>\n      <td>Notification time out: &lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2015-07-29</td>\n      <td>19:04:12,394</td>\n      <td>INFO</td>\n      <td>/10.10.34.11</td>\n      <td>3888:QuorumCnxManager$Listener</td>\n      <td>493</td>\n      <td>Received connection request /10.10.34.11:45307</td>\n      <td>E40</td>\n      <td>Received connection request /&lt;*&gt;:&lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2015-07-29</td>\n      <td>19:04:29,071</td>\n      <td>WARN</td>\n      <td>SendWorker</td>\n      <td>188978561024:QuorumCnxManager$SendWorker</td>\n      <td>688</td>\n      <td>Send worker leaving thread</td>\n      <td>E42</td>\n      <td>Send worker leaving thread</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nFirst 3 rows of Thunderbird_2k.log_structured.csv:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   LineId Label   Timestamp        Date   User Month  Day      Time  \\\n0       1     -  1131566461  2005.11.09  dn228   Nov    9  12:01:01   \n1       2     -  1131566461  2005.11.09  dn228   Nov    9  12:01:01   \n2       3     -  1131566461  2005.11.09  dn228   Nov    9  12:01:01   \n\n      Location        Component     PID  \\\n0  dn228/dn228  crond(pam_unix)  2915.0   \n1  dn228/dn228  crond(pam_unix)  2915.0   \n2  dn228/dn228            crond  2916.0   \n\n                                   Content EventId  \\\n0             session closed for user root    E117   \n1  session opened for user root by (uid=0)    E118   \n2  (root) CMD (run-parts /etc/cron.hourly)      E3   \n\n                             EventTemplate  \n0             session closed for user root  \n1  session opened for user root by (uid=0)  \n2  (root) CMD (run-parts /etc/cron.hourly)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LineId</th>\n      <th>Label</th>\n      <th>Timestamp</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>Time</th>\n      <th>Location</th>\n      <th>Component</th>\n      <th>PID</th>\n      <th>Content</th>\n      <th>EventId</th>\n      <th>EventTemplate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-</td>\n      <td>1131566461</td>\n      <td>2005.11.09</td>\n      <td>dn228</td>\n      <td>Nov</td>\n      <td>9</td>\n      <td>12:01:01</td>\n      <td>dn228/dn228</td>\n      <td>crond(pam_unix)</td>\n      <td>2915.0</td>\n      <td>session closed for user root</td>\n      <td>E117</td>\n      <td>session closed for user root</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>-</td>\n      <td>1131566461</td>\n      <td>2005.11.09</td>\n      <td>dn228</td>\n      <td>Nov</td>\n      <td>9</td>\n      <td>12:01:01</td>\n      <td>dn228/dn228</td>\n      <td>crond(pam_unix)</td>\n      <td>2915.0</td>\n      <td>session opened for user root by (uid=0)</td>\n      <td>E118</td>\n      <td>session opened for user root by (uid=0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>-</td>\n      <td>1131566461</td>\n      <td>2005.11.09</td>\n      <td>dn228</td>\n      <td>Nov</td>\n      <td>9</td>\n      <td>12:01:01</td>\n      <td>dn228/dn228</td>\n      <td>crond</td>\n      <td>2916.0</td>\n      <td>(root) CMD (run-parts /etc/cron.hourly)</td>\n      <td>E3</td>\n      <td>(root) CMD (run-parts /etc/cron.hourly)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nFirst 3 rows of Spark_2k.log_structured.csv:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   LineId      Date      Time Level                              Component  \\\n0       1  17/06/09  20:10:40  INFO  executor.CoarseGrainedExecutorBackend   \n1       2  17/06/09  20:10:40  INFO                  spark.SecurityManager   \n2       3  17/06/09  20:10:40  INFO                  spark.SecurityManager   \n\n                                           Content EventId  \\\n0  Registered signal handlers for [TERM, HUP, INT]     E22   \n1                 Changing view acls to: yarn,curi      E5   \n2               Changing modify acls to: yarn,curi      E4   \n\n                                     EventTemplate  \n0  Registered signal handlers for [TERM, HUP, INT]  \n1                       Changing view acls to: <*>  \n2                     Changing modify acls to: <*>  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LineId</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Level</th>\n      <th>Component</th>\n      <th>Content</th>\n      <th>EventId</th>\n      <th>EventTemplate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>17/06/09</td>\n      <td>20:10:40</td>\n      <td>INFO</td>\n      <td>executor.CoarseGrainedExecutorBackend</td>\n      <td>Registered signal handlers for [TERM, HUP, INT]</td>\n      <td>E22</td>\n      <td>Registered signal handlers for [TERM, HUP, INT]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>17/06/09</td>\n      <td>20:10:40</td>\n      <td>INFO</td>\n      <td>spark.SecurityManager</td>\n      <td>Changing view acls to: yarn,curi</td>\n      <td>E5</td>\n      <td>Changing view acls to: &lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>17/06/09</td>\n      <td>20:10:40</td>\n      <td>INFO</td>\n      <td>spark.SecurityManager</td>\n      <td>Changing modify acls to: yarn,curi</td>\n      <td>E4</td>\n      <td>Changing modify acls to: &lt;*&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nFirst 3 rows of Hadoop_2k.log_structured.csv:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   LineId        Date          Time Level Process  \\\n0       1  2015-10-18  18:01:47,978  INFO    main   \n1       2  2015-10-18  18:01:48,963  INFO    main   \n2       3  2015-10-18  18:01:48,963  INFO    main   \n\n                                        Component  \\\n0  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n1  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n2  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n\n                                             Content EventId  \\\n0  Created MRAppMaster for application appattempt...     E29   \n1                             Executing with tokens:     E42   \n2  Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...     E61   \n\n                                       EventTemplate  \n0  Created MRAppMaster for application appattempt...  \n1                             Executing with tokens:  \n2  Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LineId</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Level</th>\n      <th>Process</th>\n      <th>Component</th>\n      <th>Content</th>\n      <th>EventId</th>\n      <th>EventTemplate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2015-10-18</td>\n      <td>18:01:47,978</td>\n      <td>INFO</td>\n      <td>main</td>\n      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n      <td>Created MRAppMaster for application appattempt...</td>\n      <td>E29</td>\n      <td>Created MRAppMaster for application appattempt...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2015-10-18</td>\n      <td>18:01:48,963</td>\n      <td>INFO</td>\n      <td>main</td>\n      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n      <td>Executing with tokens:</td>\n      <td>E42</td>\n      <td>Executing with tokens:</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2015-10-18</td>\n      <td>18:01:48,963</td>\n      <td>INFO</td>\n      <td>main</td>\n      <td>org.apache.hadoop.mapreduce.v2.app.MRAppMaster</td>\n      <td>Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...</td>\n      <td>E61</td>\n      <td>Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nFirst 3 rows of Apache_2k.log_structured.csv:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   LineId                      Time   Level  \\\n0       1  Sun Dec 04 04:47:44 2005  notice   \n1       2  Sun Dec 04 04:47:44 2005   error   \n2       3  Sun Dec 04 04:51:08 2005  notice   \n\n                                             Content EventId  \\\n0  workerEnv.init() ok /etc/httpd/conf/workers2.p...      E2   \n1            mod_jk child workerEnv in error state 6      E3   \n2  jk2_init() Found child 6725 in scoreboard slot 10      E1   \n\n                                       EventTemplate  \n0                            workerEnv.init() ok <*>  \n1          mod_jk child workerEnv in error state <*>  \n2  jk2_init() Found child <*> in scoreboard slot <*>  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LineId</th>\n      <th>Time</th>\n      <th>Level</th>\n      <th>Content</th>\n      <th>EventId</th>\n      <th>EventTemplate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Sun Dec 04 04:47:44 2005</td>\n      <td>notice</td>\n      <td>workerEnv.init() ok /etc/httpd/conf/workers2.p...</td>\n      <td>E2</td>\n      <td>workerEnv.init() ok &lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Sun Dec 04 04:47:44 2005</td>\n      <td>error</td>\n      <td>mod_jk child workerEnv in error state 6</td>\n      <td>E3</td>\n      <td>mod_jk child workerEnv in error state &lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Sun Dec 04 04:51:08 2005</td>\n      <td>notice</td>\n      <td>jk2_init() Found child 6725 in scoreboard slot 10</td>\n      <td>E1</td>\n      <td>jk2_init() Found child &lt;*&gt; in scoreboard slot &lt;*&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"./data\")\n",
    "\n",
    "file_names = [\n",
    "    \"Zookeeper_2k.log_structured.csv\",\n",
    "    \"Thunderbird_2k.log_structured.csv\",\n",
    "    \"Spark_2k.log_structured.csv\",\n",
    "    \"Hadoop_2k.log_structured.csv\",\n",
    "    \"Apache_2k.log_structured.csv\"\n",
    "]\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = data_dir / file_name\n",
    "    print(f\"First 3 rows of {file_name}:\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    display(df.head(3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "source": [
    "For simplicity, assume that our task is to simply label where the data is coming from based on the `Content` field of each row.\n",
    "\n",
    "Let's define a custom `Signature` towards this purpose:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClassifier(dspy.Signature):\n",
    "    \"\"\"Label the data source based on the content. \"\"\"\n",
    "    content: str = dspy.InputField()\n",
    "    label: Literal['apache', 'hadoop', 'spark', 'thunderbird', 'zookeeper'] = dspy.OutputField()"
   ]
  },
  {
   "source": [
    "Next, let's read some random data rows from the log files as DSPy `Example` objects."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Example({'content': 'Interrupting SendWorker', 'label': 'zookeeper'}) (input_keys={'content', 'label'})\nExample({'content': 'Received connection request /10.10.34.11:48609', 'label': 'zookeeper'}) (input_keys={'content', 'label'})\nExample({'content': 'Connection request from old client /10.10.34.11:58424; will be dropped if server is in r-o mode', 'label': 'zookeeper'}) (input_keys={'content', 'label'})\nExample({'content': 'synchronized to 10.100.18.250, stratum 3', 'label': 'thunderbird'}) (input_keys={'content', 'label'})\nExample({'content': 'data_thread() got not answer from any [Thunderbird_A8] datasource', 'label': 'thunderbird'}) (input_keys={'content', 'label'})\nExample({'content': 'probe new device 0x1028:0x0013:0x1028:0x016c: bus 2:slot 14:func 0', 'label': 'thunderbird'}) (input_keys={'content', 'label'})\nExample({'content': 'Finished task 0.0 in stage 29.0 (TID 1320). 2128 bytes result sent to driver', 'label': 'spark'}) (input_keys={'content', 'label'})\nExample({'content': 'Finished task 3.0 in stage 8.0 (TID 358). 2141 bytes result sent to driver', 'label': 'spark'}) (input_keys={'content', 'label'})\nExample({'content': 'Times: total = 41, boot = 16, init = 25, finish = 0', 'label': 'spark'}) (input_keys={'content', 'label'})\nExample({'content': 'Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 317 seconds.  Will retry shortly ...', 'label': 'hadoop'}) (input_keys={'content', 'label'})\nExample({'content': 'Reduce slow start threshold not met. completedMapsForReduceSlowstart 1', 'label': 'hadoop'}) (input_keys={'content', 'label'})\nExample({'content': 'ERROR IN CONTACTING RM.', 'label': 'hadoop'}) (input_keys={'content', 'label'})\nExample({'content': 'mod_jk child workerEnv in error state 6', 'label': 'apache'}) (input_keys={'content', 'label'})\nExample({'content': 'workerEnv.init() ok /etc/httpd/conf/workers2.properties', 'label': 'apache'}) (input_keys={'content', 'label'})\nExample({'content': 'jk2_init() Found child 5033 in scoreboard slot 8', 'label': 'apache'}) (input_keys={'content', 'label'})\n"
     ]
    }
   ],
   "source": [
    "file_label_mapping = {\n",
    "    \"Zookeeper_2k.log_structured.csv\": \"zookeeper\",\n",
    "    \"Thunderbird_2k.log_structured.csv\": \"thunderbird\",\n",
    "    \"Spark_2k.log_structured.csv\": \"spark\",\n",
    "    \"Hadoop_2k.log_structured.csv\": \"hadoop\",\n",
    "    \"Apache_2k.log_structured.csv\": \"apache\"\n",
    "}\n",
    "\n",
    "def create_random_examples(n_examples=3):\n",
    "    examples = []\n",
    "\n",
    "    for file_name, label in file_label_mapping.items():\n",
    "        file_path = data_dir / file_name\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Sample 3 random rows and extract the \"Content\" field\n",
    "        sampled_rows = df.sample(n=n_examples, random_state=42)['Content'].tolist()\n",
    "        \n",
    "        # Create Example objects\n",
    "        for content in sampled_rows:\n",
    "            example = dspy.Example(content=content, label=label).with_inputs(\"content\", \"label\")\n",
    "            examples.append(example)\n",
    "    return examples\n",
    "\n",
    "examples = create_random_examples()\n",
    "# Print the generated Example objects\n",
    "for ex in examples:\n",
    "    print(ex)"
   ]
  },
  {
   "source": [
    "Let's see how a `ChainOfThought` module does in this task:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Content: Interrupting SendWorker\n",
      "Predicted: apache, Actual: zookeeper\n",
      "Reasoning: The content appears to be related to a network or distributed system, mentioning a \"SendWorker\" which is a common concept in distributed systems.\n",
      "Correct: False\n",
      "\n",
      "Content: Received connection request /10.10.34.11:48609\n",
      "Predicted: zookeeper, Actual: zookeeper\n",
      "Reasoning: The connection request is coming from a client with IP address 10.10.34.11, which is a common IP address range used by Apache ZooKeeper servers.\n",
      "Correct: True\n",
      "\n",
      "Content: Connection request from old client /10.10.34.11:58424; will be dropped if server is in r-o mode\n",
      "Predicted: apache, Actual: zookeeper\n",
      "Reasoning: This content appears to be related to a connection request and mentions a server, which is typical of distributed systems and network communication. The mention of \"r-o mode\" suggests that the server may be in read-only mode, which is a common configuration in distributed systems.\n",
      "Correct: False\n",
      "\n",
      "Content: synchronized to 10.100.18.250, stratum 3\n",
      "Predicted: apache, Actual: thunderbird\n",
      "Reasoning: The content appears to be a block chain node synchronization message, indicating the node is connected to a peer at IP address 10.100.18.250.\n",
      "Correct: False\n",
      "\n",
      "Content: data_thread() got not answer from any [Thunderbird_A8] datasource\n",
      "Predicted: thunderbird, Actual: thunderbird\n",
      "Reasoning: The content mentions \"Thunderbird_A8\" which is a known datasource related to Thunderbird.\n",
      "Correct: True\n",
      "\n",
      "Content: probe new device 0x1028:0x0013:0x1028:0x016c: bus 2:slot 14:func 0\n",
      "Predicted: apache, Actual: thunderbird\n",
      "Reasoning: The content appears to be a USB device probe message, which is commonly used in Linux systems.\n",
      "Correct: False\n",
      "\n",
      "Content: Finished task 0.0 in stage 29.0 (TID 1320). 2128 bytes result sent to driver\n",
      "Predicted: spark, Actual: spark\n",
      "Reasoning: The content suggests a Spark job, as it mentions a stage and a TID (Task ID), which are common in Spark's job execution.\n",
      "Correct: True\n",
      "\n",
      "Content: Finished task 3.0 in stage 8.0 (TID 358). 2141 bytes result sent to driver\n",
      "Predicted: spark, Actual: spark\n",
      "Reasoning: The content appears to be a log message from a Spark application, indicating the completion of a task and the sending of the result to the driver.\n",
      "Correct: True\n",
      "\n",
      "Content: Times: total = 41, boot = 16, init = 25, finish = 0\n",
      "Predicted: hadoop, Actual: spark\n",
      "Reasoning: The content appears to be a system boot time report, which is commonly used in Hadoop and Spark environments to monitor job execution times.\n",
      "Correct: False\n",
      "\n",
      "Content: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 317 seconds.  Will retry shortly ...\n",
      "Predicted: hadoop, Actual: hadoop\n",
      "Reasoning: The content suggests a failure to renew a lease for a DFSClient, which is a component of the Hadoop Distributed File System (HDFS).\n",
      "Correct: True\n",
      "\n",
      "Content: Reduce slow start threshold not met. completedMapsForReduceSlowstart 1\n",
      "Predicted: hadoop, Actual: hadoop\n",
      "Reasoning: The content suggests that the data source is related to a distributed computing system, specifically a MapReduce job, where the slow start threshold is not met.\n",
      "Correct: True\n",
      "\n",
      "Content: ERROR IN CONTACTING RM.\n",
      "Predicted: hadoop, Actual: hadoop\n",
      "Reasoning: The error message suggests a problem with a resource manager, which is a common component in big data processing systems.\n",
      "Correct: True\n",
      "\n",
      "Content: mod_jk child workerEnv in error state 6\n",
      "Predicted: apache, Actual: apache\n",
      "Reasoning: The error message 'mod_jk child workerEnv in error state 6' is related to the Apache HTTP Server module mod_jk, which is used to connect Apache to other servers, such as Tomcat. The error message specifically mentions 'mod_jk', indicating that the issue is related to the Apache server.\n",
      "Correct: True\n",
      "\n",
      "Content: workerEnv.init() ok /etc/httpd/conf/workers2.properties\n",
      "Predicted: apache, Actual: apache\n",
      "Reasoning: The content suggests that the data source is related to Apache HTTP Server configuration.\n",
      "Correct: True\n",
      "\n",
      "Content: jk2_init() Found child 5033 in scoreboard slot 8\n",
      "Predicted: apache, Actual: apache\n",
      "Reasoning: The given content is related to a child process being found in a scoreboard slot, which is a common concept in Apache and its related projects.\n",
      "Correct: True\n",
      "\n",
      "Success Rate: 66.67%\n"
     ]
    }
   ],
   "source": [
    "dataclassifier_cot = dspy.ChainOfThought(DataClassifier)\n",
    "\n",
    "# Initialize counters\n",
    "total_examples = len(examples)\n",
    "correct_classifications = 0\n",
    "\n",
    "# Process each example and query the classifier\n",
    "for example in examples:\n",
    "    response_cot = dataclassifier_cot(content=example.content)\n",
    "    predicted_label = response_cot.label\n",
    "\n",
    "    # Check correctness\n",
    "    correct = predicted_label == example.label\n",
    "    correct_classifications += correct\n",
    "\n",
    "    # Print reasoning\n",
    "    print(f\"Content: {example.content}\")\n",
    "    print(f\"Predicted: {predicted_label}, Actual: {example.label}\")\n",
    "    print(f\"Reasoning: {response_cot.reasoning}\")\n",
    "    print(f\"Correct: {correct}\\n\")\n",
    "\n",
    "# Compute and display success rate\n",
    "success_rate = correct_classifications / total_examples * 100\n",
    "print(f\"Success Rate: {success_rate:.2f}%\")"
   ]
  },
  {
   "source": [
    "OK, with this we reaches a success rate of roughly 67%. To enhance the classification accuracy, let's `Optimize` our LLM using the concept of [DSPy optimizers](https://dspy.ai/learn/optimization/optimizers/).\n",
    "\n",
    "To do this, we first need an [Evaluation metric](https://dspy.ai/learn/evaluation/metrics/). For a classifcation task, this is relatively simple: we do a 0-1 loss based on correct labeling, which may be defined as a lambda function:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = (lambda x, y, trace=None: x.label == y.label)"
   ]
  },
  {
   "source": [
    "Next, we need to choose an optimizer to use from the [list of DSPy optimizers](https://dspy.ai/learn/optimization/optimizers/). As mentioned in DSPy's website, there isn't a single heuristic to choose the correct optimizer to use:\n",
    "```\n",
    "Ultimately, finding the ‘right’ optimizer to use & the best configuration for your task will require experimentation. \n",
    "Success in DSPy is still an iterative process - getting the best performance on your task will require you to explore and iterate.\n",
    "```\n",
    "Let's try `MIPROV2`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Metric: 10.00 / 15 (66.7%): 100%|██████████| 15/15 [00:00<00:00, 807.62it/s]2025/02/09 03:46:51 INFO dspy.evaluate.evaluate: Average Metric: 10 / 15 (66.7%)\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "66.67"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "trainset = create_random_examples(n_examples=5)\n",
    "devset = create_random_examples(n_examples=3)\n",
    "\n",
    "converted_trainset = [ex.with_inputs(\"content\") for ex in trainset]\n",
    "converted_devset   = [ex.with_inputs(\"content\") for ex in devset]\n",
    "\n",
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dataclassifier_cot\n",
    "\n",
    "    def forward(self, content):\n",
    "        return self.prog(content=content)\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=converted_devset, metric=metric, num_threads=8, display_progress=True, display_table=False)\n",
    "program = CoT()\n",
    "evaluate(program, devset=converted_devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 7\n",
      "minibatch: False\n",
      "num_candidates: 5\n",
      "valset size: 20\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=5 sets of demonstrations...\n",
      "Optimizing program with MIPRO...\n",
      "Bootstrapping set 1/5\n",
      "Bootstrapping set 2/5\n",
      "Bootstrapping set 3/5\n",
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00, 226.54it/s]\n",
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 4/5\n",
      "\n",
      " 20%|██        | 1/5 [00:00<00:00, 259.66it/s]\n",
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/5\n",
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00, 254.82it/s]\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Label the data source based on the content. \n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Using the content of the log message, identify the relevant Apache system and provide a step-by-step reasoning for your classification.\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a zookeeper administrator tasked with identifying the source of a log message. Label the content based on the description provided, and provide a step-by-step reasoning explanation for your classification.\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Classify the given zookeeper event log content into one of the categories (apache, hadoop, spark, thunderbird, zookeeper) based on the technical details provided in the content string, and provide a reasoning step explaining the thought process behind the classification.\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Provide a detailed classification of the content, including a clear explanation of the reasoning behind the classification, and output the corresponding label.\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 7 - Full Evaluation of Default Program ==\n",
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Average Metric: 12.00 / 20 (60.0%): 100%|██████████| 20/20 [00:00<00:00, 882.65it/s]2025/02/09 03:49:24 INFO dspy.evaluate.evaluate: Average Metric: 12 / 20 (60.0%)\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 60.0\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 7 =====\n",
      "\n",
      "Average Metric: 13.00 / 20 (65.0%): 100%|██████████| 20/20 [00:00<00:00, 631.63it/s]2025/02/09 03:49:24 INFO dspy.evaluate.evaluate: Average Metric: 13 / 20 (65.0%)\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 65.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 65.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [60.0, 65.0]\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 65.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 7 =====\n",
      "\n",
      "Average Metric: 14.00 / 20 (70.0%): 100%|██████████| 20/20 [00:00<00:00, 1124.42it/s]2025/02/09 03:49:24 INFO dspy.evaluate.evaluate: Average Metric: 14 / 20 (70.0%)\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 70.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [60.0, 65.0, 70.0]\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 70.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 7 =====\n",
      "\n",
      "Average Metric: 15.00 / 20 (75.0%): 100%|██████████| 20/20 [00:00<00:00, 707.97it/s]2025/02/09 03:49:24 INFO dspy.evaluate.evaluate: Average Metric: 15 / 20 (75.0%)\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 75.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [60.0, 65.0, 70.0, 75.0]\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 7 =====\n",
      "\n",
      "Average Metric: 14.00 / 20 (70.0%): 100%|██████████| 20/20 [00:00<00:00, 797.79it/s]2025/02/09 03:49:24 INFO dspy.evaluate.evaluate: Average Metric: 14 / 20 (70.0%)\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.0 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [60.0, 65.0, 70.0, 75.0, 70.0]\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 7 =====\n",
      "\n",
      "Average Metric: 12.00 / 20 (60.0%): 100%|██████████| 20/20 [00:00<00:00, 701.07it/s]2025/02/09 03:49:24 INFO dspy.evaluate.evaluate: Average Metric: 12 / 20 (60.0%)\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 60.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [60.0, 65.0, 70.0, 75.0, 70.0, 60.0]\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/02/09 03:49:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 7 =====\n",
      "\n",
      "Average Metric: 15.00 / 20 (75.0%): 100%|██████████| 20/20 [00:00<00:00, 968.82it/s]2025/02/09 03:49:25 INFO dspy.evaluate.evaluate: Average Metric: 15 / 20 (75.0%)\n",
      "2025/02/09 03:49:25 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/02/09 03:49:25 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [60.0, 65.0, 70.0, 75.0, 70.0, 60.0, 75.0]\n",
      "2025/02/09 03:49:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 75.0\n",
      "2025/02/09 03:49:25 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/02/09 03:49:25 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 75.0!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teleprompter = dspy.teleprompt.MIPROv2(\n",
    "    metric=metric,\n",
    "    auto=\"light\",\n",
    ")\n",
    "\n",
    "# Optimize program\n",
    "print(f\"Optimizing program with MIPRO...\")\n",
    "\n",
    "optimized_program = teleprompter.compile(\n",
    "    program.deepcopy(),\n",
    "    trainset=converted_trainset,\n",
    "    max_bootstrapped_demos=3,\n",
    "    max_labeled_demos=4,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluate optimized program...\n",
      "Average Metric: 12.00 / 15 (80.0%): 100%|██████████| 15/15 [00:00<00:00, 880.70it/s]2025/02/09 03:51:35 INFO dspy.evaluate.evaluate: Average Metric: 12 / 15 (80.0%)\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "print(f\"Evaluate optimized program...\")\n",
    "evaluate(optimized_program, devset=converted_devset)"
   ]
  },
  {
   "source": [
    "Seems like our success rate increased to 80% as a result of optimization. Let's save our model as a `json` file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_program.save(f\"mipro_optimized.json\")"
   ]
  },
  {
   "source": [
    "We can take a look at the final prompt using `lm.inspect_history`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n\n\n\u001b[34m[2025-02-09T03:51:35.793939]\u001b[0m\n\n\u001b[31mSystem message:\u001b[0m\n\nYour input fields are:\n1. `content` (str)\n\nYour output fields are:\n1. `reasoning` (str)\n2. `label` (typing.Literal['apache', 'hadoop', 'spark', 'thunderbird', 'zookeeper'])\n\nAll interactions will be structured in the following way, with the appropriate values filled in.\n\n[[ ## content ## ]]\n{content}\n\n[[ ## reasoning ## ]]\n{reasoning}\n\n[[ ## label ## ]]\n{label}        # note: the value you produce must exactly match (no extra characters) one of: apache; hadoop; spark; thunderbird; zookeeper\n\n[[ ## completed ## ]]\n\nIn adhering to this structure, your objective is: \n        Provide a detailed classification of the content, including a clear explanation of the reasoning behind the classification, and output the corresponding label.\n\n\n\u001b[31mUser message:\u001b[0m\n\nThis is an example of the task, though some input or output fields are not supplied.\n\n[[ ## content ## ]]\nConnection broken for id 188978561024, my id = 2, error =\n\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]` (must be formatted as a valid Python typing.Literal['apache', 'hadoop', 'spark', 'thunderbird', 'zookeeper']), and then ending with the marker for `[[ ## completed ## ]]`.\n\n\n\u001b[31mAssistant message:\u001b[0m\n\n[[ ## reasoning ## ]]\nNot supplied for this particular example.\n\n[[ ## label ## ]]\nzookeeper\n\n[[ ## completed ## ]]\n\n\n\u001b[31mUser message:\u001b[0m\n\nThis is an example of the task, though some input or output fields are not supplied.\n\n[[ ## content ## ]]\nProcessed session termination for sessionid: 0x14ed93111f20050\n\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]` (must be formatted as a valid Python typing.Literal['apache', 'hadoop', 'spark', 'thunderbird', 'zookeeper']), and then ending with the marker for `[[ ## completed ## ]]`.\n\n\n\u001b[31mAssistant message:\u001b[0m\n\n[[ ## reasoning ## ]]\nNot supplied for this particular example.\n\n[[ ## label ## ]]\nzookeeper\n\n[[ ## completed ## ]]\n\n\n\u001b[31mUser message:\u001b[0m\n\nThis is an example of the task, though some input or output fields are not supplied.\n\n[[ ## content ## ]]\nInterrupting SendWorker\n\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]` (must be formatted as a valid Python typing.Literal['apache', 'hadoop', 'spark', 'thunderbird', 'zookeeper']), and then ending with the marker for `[[ ## completed ## ]]`.\n\n\n\u001b[31mAssistant message:\u001b[0m\n\n[[ ## reasoning ## ]]\nNot supplied for this particular example.\n\n[[ ## label ## ]]\nzookeeper\n\n[[ ## completed ## ]]\n\n\n\u001b[31mUser message:\u001b[0m\n\nThis is an example of the task, though some input or output fields are not supplied.\n\n[[ ## content ## ]]\nReceived connection request /10.10.34.11:48609\n\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]` (must be formatted as a valid Python typing.Literal['apache', 'hadoop', 'spark', 'thunderbird', 'zookeeper']), and then ending with the marker for `[[ ## completed ## ]]`.\n\n\n\u001b[31mAssistant message:\u001b[0m\n\n[[ ## reasoning ## ]]\nNot supplied for this particular example.\n\n[[ ## label ## ]]\nzookeeper\n\n[[ ## completed ## ]]\n\n\n\u001b[31mUser message:\u001b[0m\n\n[[ ## content ## ]]\nERROR IN CONTACTING RM.\n\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]` (must be formatted as a valid Python typing.Literal['apache', 'hadoop', 'spark', 'thunderbird', 'zookeeper']), and then ending with the marker for `[[ ## completed ## ]]`.\n\n\n\u001b[31mResponse:\u001b[0m\n\n\u001b[32m[[ ## reasoning ## ]]\nThe content suggests an error in contacting the Resource Manager (RM), which is a component of the Hadoop ecosystem.\n\n[[ ## label ## ]]\nhadoop\n\n[[ ## completed ## ]]\u001b[0m\n\n\n\n\n\nNone\n"
     ]
    }
   ],
   "source": [
    "print(lm.inspect_history(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}